{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description:                                                                                                                   \n",
    " The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\n",
    " \n",
    " Attributes:\n",
    " 1. Glucose Level\n",
    " 2. BMI\n",
    " 3. Blood pressure\n",
    " 4. Pregnancies\n",
    " 5. Skin thickness\n",
    " 6. Insulin\n",
    " 7. Diabetes pedigree function\n",
    " 8. Age\n",
    " 9. Outcome\n",
    "\n",
    " Step 0: Import libraries and Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dataset = pd.read_csv('..\\Datasets\\diabetes.csv')\n",
    "dataset_X = dataset.iloc[:,[1, 4, 5, 7]].values\n",
    "dataset_Y = dataset.iloc[:,8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[148. ,   0. ,  33.6,  50. ],\n",
       "       [ 85. ,   0. ,  26.6,  31. ],\n",
       "       [183. ,   0. ,  23.3,  32. ],\n",
       "       ...,\n",
       "       [121. , 112. ,  26.2,  30. ],\n",
       "       [126. ,   0. ,  30.1,  47. ],\n",
       "       [ 93. ,   0. ,  30.4,  23. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "dataset_scaled = sc.fit_transform(dataset_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_scaled = pd.DataFrame(dataset_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset_scaled\n",
    "Y = dataset_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3\n",
      "0  0.743719  0.000000  0.500745  0.483333\n",
      "1  0.427136  0.000000  0.396423  0.166667\n",
      "2  0.919598  0.000000  0.347243  0.183333\n",
      "3  0.447236  0.111111  0.418778  0.000000\n",
      "4  0.688442  0.198582  0.642325  0.200000\n"
     ]
    }
   ],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.20, random_state = 42, stratify = dataset['Outcome'] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel = 'linear', random_state = 42)\n",
    "svc.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7337662337662337"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svc, open('diabetesmodel.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "model = pickle.load(open('diabetesmodel.pkl','rb'))\n",
    "print(model.predict(sc.transform(np.array([[86, 66, 26.6, 31]]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7337662337662337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "dtc.fit(X_train, Y_train)\n",
    "\n",
    "# Predict the class labels for the test set\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7337662337662337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Creating an instance of KNeighborsClassifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Training the model using the training data\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "# Testing the model on the test data\n",
    "accuracy = knn.score(X_test, Y_test)\n",
    "\n",
    "# Printing the accuracy\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.7337662337662337\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a Random Forest classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rfc.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Evaluate model performance using accuracy score\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print('Random Forest accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes accuracy: 0.7337662337662337\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Initialize a Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "gnb.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Evaluate model performance using accuracy score\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print('Naive Bayes accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.7532467532467533\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Convert data to XGBoost DMatrix format\n",
    "train_dmatrix = xgb.DMatrix(X_train, label=Y_train)\n",
    "test_dmatrix = xgb.DMatrix(X_test, label=Y_test)\n",
    "\n",
    "# Set XGBoost parameters\n",
    "params = {'objective': 'binary:logistic', 'max_depth': 3, 'learning_rate': 0.1}\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.train(params, train_dmatrix, num_boost_round=100)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = xgb_model.predict(test_dmatrix)\n",
    "\n",
    "# Convert predicted probabilities to binary labels\n",
    "y_pred_binary = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "\n",
    "# Evaluate model performance using accuracy score\n",
    "accuracy = accuracy_score(Y_test, y_pred_binary)\n",
    "print('XGBoost accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: mean=0.674273 (std=0.041631)\n",
      "Naive Bayes: mean=0.766949 (std=0.050300)\n",
      "XGBOOSTER: mean=0.750767 (std=0.056714)\n",
      "k-NN: mean=0.741169 (std=0.063480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: mean=0.776705 (std=0.069659)\n",
      "Random Forest: mean=0.732919 (std=0.061357)\n",
      "Best Algorithm: SVM\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Create a list of algorithms to evaluate\n",
    "models = []\n",
    "models.append(('Decision Tree', DecisionTreeClassifier()))\n",
    "models.append(('Naive Bayes', GaussianNB()))\n",
    "models.append(('XGBOOSTER', xgb.XGBClassifier(objective='binary:logistic', max_depth=3, learning_rate=0.1)))\n",
    "models.append(('k-NN', KNeighborsClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "\n",
    "# Evaluate each algorithm using 10-fold cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"%s: mean=%f (std=%f)\" % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "# Select the model with the best accuracy\n",
    "import numpy as np\n",
    "best_idx = np.argmax([np.mean(r) for r in results])\n",
    "best_name = names[best_idx]\n",
    "print('Best Algorithm:', best_name)\n",
    "# Select the model with the highest accuracy\n",
    "#best_model = max([(logreg_accuracy, logreg_model), (rf_accuracy, rf_model), (svm_accuracy, svm_model)], key=lambda x: x[0])[1]\n",
    "\n",
    "# Save the best model using pickle\n",
    "#with open('best_model.pkl', 'wb') as model_file:\n",
    "#    pickle.dump(best_model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Replace these with your actual accuracy values\n",
    "models = ['Decision Tree', 'Naive Bayes', 'XGBooster', 'KNN', 'SVc', 'Random Forest']\n",
    "accuracies = [0.674273, 0.766949, 0.750767, 0.741169, 0.876705 , 0.732919 ]\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(x=models, y=accuracies, palette='viridis')\n",
    "plt.ylim(0.7, 1.0)  # Set y-axis limits for better visualization\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
